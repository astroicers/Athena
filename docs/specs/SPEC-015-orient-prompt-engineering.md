# SPEC-015ï¼šOrient Prompt å·¥ç¨‹å‡ç´š

> å€Ÿé¡ PentestGPTã€hackingBuddyGPTã€autopentest-aiã€AttackGenã€PentAGI ç­‰é–‹æºå°ˆæ¡ˆçš„ prompt å·¥ç¨‹æ¨¡å¼ï¼Œå‡ç´š `orient_engine.py` çš„ LLM prompt çµæ§‹ï¼Œæå‡æˆ°è¡“åˆ†ææ·±åº¦ã€‚

| æ¬„ä½ | å…§å®¹ |
|------|------|
| **è¦æ ¼ ID** | SPEC-015 |
| **é—œè¯ ADR** | ADR-013ï¼ˆOrient Prompt ç­–ç•¥ï¼‰ã€ADR-005ï¼ˆPentestGPT Orient å¼•æ“ï¼‰ |
| **ä¼°ç®—è¤‡é›œåº¦** | ä¸­ |
| **å»ºè­°æ¨¡å‹** | Sonnet |
| **HITL ç­‰ç´š** | standard |

---

## ğŸ¯ ç›®æ¨™ï¼ˆGoalï¼‰

> å°‡ `orient_engine.py` çš„ 40 è¡Œå–®ä¸€ prompt å‡ç´šç‚ºçµæ§‹åŒ–çš„ system + user é›™ prompt æ¶æ§‹ï¼Œèå…¥ 5 å€‹é–‹æº prompt å·¥ç¨‹æ¨¡å¼ï¼š(1) ä»»å‹™æ¨¹æ³¨å…¥ã€(2) system/user åˆ†é›¢èˆ‡è§’è‰²åˆç´„ã€(3) Kill Chain æˆ°è¡“æ¨ç†ã€(4) è¼•é‡ä¸‰å±¤è¨˜æ†¶ã€(5) åˆ†é¡æƒ…å ±æ³¨å…¥ã€‚å¤–éƒ¨ä»‹é¢ `analyze()` å›å‚³çµæ§‹ä¸è®Šï¼Œ`MOCK_LLM=true` è·¯å¾‘ä¸å—å½±éŸ¿ã€‚

---

## ğŸ“¥ è¼¸å…¥è¦æ ¼ï¼ˆInputsï¼‰

| åƒæ•¸åç¨± | å‹åˆ¥ | ä¾†æº | é™åˆ¶æ¢ä»¶ |
|----------|------|------|----------|
| `operation_id` | str | caller | å·²å­˜åœ¨çš„ä½œæˆ° ID |
| `observe_summary` | str | `fact_collector.summarize()` | <= 1000 chars |
| `MOCK_LLM` | bool | config | true = ç›´æ¥å›å‚³ `_MOCK_RECOMMENDATION`ï¼Œä¸å‘¼å« `_build_prompt()` |

**æ–°å¢æŸ¥è©¢çš„ DB è¡¨ï¼ˆå…¨éƒ¨å·²å­˜åœ¨æ–¼ `database.py`ï¼‰ï¼š**

| è¡¨ | ä½¿ç”¨æ¬„ä½ | ç”¨é€” | Pattern |
|----|----------|------|---------|
| `mission_steps` | step_number, technique_name, status, technique_id, engine, target_label | ä»»å‹™æ¨¹æ³¨å…¥ | 1 |
| `ooda_iterations` | iteration_number, observe_summary, act_summary, completed_at | å·¥ä½œè¨˜æ†¶ï¼ˆè¿‘ 3 è¼ªï¼‰ | 5 |
| `recommendations` | situation_assessment, recommended_technique_id, reasoning_text | æƒ…ç¯€è¨˜æ†¶ï¼ˆå‰ 2 æ¬¡ï¼‰ | 5 |
| `techniques` | tactic, tactic_idï¼ˆJOIN technique_executionsï¼‰ | Kill Chain æˆ°è¡“é€²ç¨‹ | 4 |
| `facts` | category, trait, value | åˆ†é¡æƒ…å ± | 2 |

---

## ğŸ“¤ è¼¸å‡ºè¦æ ¼ï¼ˆExpected Outputï¼‰

### 1. `_ORIENT_SYSTEM_PROMPT`ï¼ˆéœæ…‹å¸¸æ•¸ï¼Œ~200 tokensï¼‰

è§’è‰²åˆç´„ + 5 å€‹åˆ†ææ¡†æ¶æŒ‡ä»¤ï¼š

```
You are the Orient phase intelligence advisor for Athena C5ISR cyber operations platform.
Your role: analyze the current operational situation and produce actionable tactical
recommendations for the commander.

Your analytical framework:

1. KILL CHAIN PROGRESSION â€” reason through MITRE ATT&CK tactic stages in order:
   TA0001 (Initial Access) â†’ TA0002 (Execution) â†’ TA0003 (Persistence) â†’
   TA0004 (Privilege Escalation) â†’ TA0005 (Defense Evasion) â†’
   TA0006 (Credential Access) â†’ TA0007 (Discovery) â†’
   TA0008 (Lateral Movement) â†’ TA0009 (Collection) â†’ TA0010 (Exfiltration)
   Ask: "What stage are we at? What is the logical next stage?"

2. NEGATIVE BRANCH PRUNING â€” when a technique has failed, infer WHY and eliminate
   the entire sub-branch. Example: if T1003.001 (LSASS) failed, consider that EDR
   may be active â€” avoid other memory-access techniques; pivot to token manipulation
   or living-off-the-land.

3. PREREQUISITE VERIFICATION â€” only recommend techniques whose prerequisites are
   confirmed by the collected intelligence (credentials, privilege level, compromised hosts).

4. ENGINE ROUTING â€” prefer Caldera for standard MITRE techniques with known ability IDs;
   recommend Shannon only for adaptive execution in unknown defensive environments.

5. RISK CALIBRATION â€” assign risk_level based on detection likelihood, not just impact:
   low = living-off-the-land, medium = known-bad tools (Mimikatz),
   high = noisy lateral movement, critical = destructive/exfiltration operations.

Output format: respond with ONLY valid JSON matching the specified schema.
No markdown, no explanation outside the JSON.
```

### 2. `_ORIENT_USER_PROMPT_TEMPLATE`ï¼ˆå‹•æ…‹ï¼Œper-call çµ„è£ï¼‰â€” 8 æ®µè½

```
## OPERATION BRIEF
Code: {op_code} | Codename: {op_codename}
Strategic Intent: {strategic_intent}
Status: {status} | Threat Level: {threat_level} | Iteration: {iteration_count}

## MISSION TASK TREE
{mission_task_tree}

## KILL CHAIN POSITION
Tactics completed: {executed_tactics}
Current stage: {current_stage}

## OPERATIONAL HISTORY (last 3 cycles)
{ooda_history}

## PREVIOUS ORIENT ASSESSMENTS (last 2)
{previous_assessments}

## CURRENT INTELLIGENCE
CREDENTIAL INTELLIGENCE:
{credential_facts}

NETWORK INTELLIGENCE:
{network_facts}

HOST INTELLIGENCE:
{host_facts}

SERVICE INTELLIGENCE:
{service_facts}

## ASSET STATUS
Targets:
{targets}

Active Agents:
{agents}

## LATEST OBSERVE SUMMARY
{observe_summary}

## COMPLETED TECHNIQUES
{completed_techniques}

## FAILED TECHNIQUES (infer defensive posture from these)
{failed_techniques}

## REQUIRED OUTPUT
Provide exactly 3 tactical options as JSON:
{{
  "situation_assessment": "2-3 sentence tactical summary",
  "recommended_technique_id": "TXXXX.XXX",
  "confidence": 0.0-1.0,
  "reasoning_text": "chain-of-thought: why this technique NOW given history and pruned branches",
  "options": [
    {{
      "technique_id": "TXXXX.XXX",
      "technique_name": "Full MITRE Name",
      "reasoning": "why this option fits current kill chain stage",
      "risk_level": "low|medium|high|critical",
      "recommended_engine": "caldera|shannon",
      "confidence": 0.0-1.0,
      "prerequisites": ["confirmed prerequisites from intelligence"]
    }}
  ]
}}
Order by confidence descending.
```

### 3. ç°½ç« è®Šæ›´

```python
# _build_prompt å›å‚³ tuple
async def _build_prompt(self, db, operation_id, observe_summary) -> tuple[str, str]

# _call_* æ¥æ”¶é›™åƒæ•¸
async def _call_llm(self, system_prompt: str, user_prompt: str) -> str
async def _call_claude(self, system_prompt: str, user_prompt: str) -> str
async def _call_openai(self, system_prompt: str, user_prompt: str) -> str
```

### 4. API å‘¼å«è®Šæ›´

Claude â€” æ–°å¢ `system` åƒæ•¸ï¼š
```python
json={
    "model": settings.CLAUDE_MODEL,
    "max_tokens": 4000,
    "temperature": 0.7,
    "system": system_prompt,
    "messages": [{"role": "user", "content": user_prompt}],
}
```

OpenAI â€” system message å‰ç½®ï¼š
```python
"messages": [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": user_prompt},
]
```

---

## âš ï¸ é‚Šç•Œæ¢ä»¶ï¼ˆEdge Casesï¼‰

| æƒ…æ³ | è™•ç†æ–¹å¼ |
|------|----------|
| `MOCK_LLM=true` | `analyze()` æå‰è¿”å› `_MOCK_RECOMMENDATION`ï¼Œä¸å‘¼å« `_build_prompt()` â€” ç„¡å½±éŸ¿ |
| ç¬¬ä¸€æ¬¡ OODA è¿­ä»£ï¼ˆç„¡æ­·å²ï¼‰ | æ­·å²æ®µè½ = ã€ŒNo prior cycles â€” first iteration.ã€ |
| `mission_steps` ç‚ºç©º | ä»»å‹™æ¨¹æ®µè½ = ã€ŒNo mission steps defined.ã€ |
| `techniques` JOIN ç„¡çµæœ | æˆ°è¡“é€²ç¨‹ = ã€ŒNone yet â€” initial reconnaissance stage.ã€ |
| `facts` ç‚ºç©º | å„åˆ†é¡æƒ…å ± = ã€ŒNo intelligence collected.ã€ |
| Token é ç®— | æ­·å² LIMIT 3ã€å»ºè­° LIMIT 2ã€æƒ…å ±æ¯é¡ LIMIT 5ï¼Œç¸½è¨ˆ ~1500 tokens user prompt + ~200 tokens system |
| LLM å›å‚³ç¼ºå°‘æ¬„ä½ | ç¾æœ‰ Phase 9.0 schema é©—è­‰é‚è¼¯ä¸è®Šï¼ˆfallback è‡³ `_MOCK_RECOMMENDATION`ï¼‰ |
| `_call_openai()` system message | OpenAI Chat Completions åŸç”Ÿæ”¯æ´ `role: "system"` â€” ç„¡ API è®Šæ›´ |
| `analyze()` å›å‚³æ ¼å¼ | **å®Œå…¨ä¸è®Š** â€” ä¸‹æ¸¸ `decision_engine.py`ã€`ooda_controller.py` ä¸å—å½±éŸ¿ |

---

## âœ… é©—æ”¶æ¨™æº–ï¼ˆDone Whenï¼‰

- [ ] `_ORIENT_SYSTEM_PROMPT` å¸¸æ•¸å®šç¾©ï¼Œå« 5 å€‹åˆ†ææ¡†æ¶æŒ‡ä»¤
- [ ] `_ORIENT_USER_PROMPT_TEMPLATE` å–ä»£ `_ORIENT_PROMPT_TEMPLATE`ï¼Œå« 8 å€‹æ®µè½
- [ ] `_build_prompt()` å›å‚³ `tuple[str, str]`
- [ ] `_build_prompt()` æŸ¥è©¢ `mission_steps`ï¼ˆä»»å‹™æ¨¹ï¼‰
- [ ] `_build_prompt()` æŸ¥è©¢ `ooda_iterations` LIMIT 3ï¼ˆå·¥ä½œè¨˜æ†¶ï¼‰
- [ ] `_build_prompt()` æŸ¥è©¢ `recommendations` LIMIT 2ï¼ˆæƒ…ç¯€è¨˜æ†¶ï¼‰
- [ ] `_build_prompt()` æŸ¥è©¢ `techniques` JOIN `technique_executions`ï¼ˆKill Chain é€²ç¨‹ï¼‰
- [ ] `_build_prompt()` æŸ¥è©¢ `facts` ä¸¦æŒ‰ `category` åˆ†çµ„
- [ ] `_call_claude()` ä½¿ç”¨ Anthropic API `system` åƒæ•¸
- [ ] `_call_openai()` å‰ç½® `{"role": "system", ...}` message
- [ ] `MOCK_LLM=true` è·¯å¾‘ä¸å—å½±éŸ¿ â€” ç¾æœ‰ SPEC-007 æ¸¬è©¦å…¨é
- [ ] æ–°å¢ 5 å€‹ prompt çµæ§‹æ¸¬è©¦ï¼ˆ`test_spec_007_ooda_services.py`ï¼‰
- [ ] `make lint` ç„¡éŒ¯èª¤

---

## ğŸš« ç¦æ­¢äº‹é …ï¼ˆOut of Scopeï¼‰

- ä¸åŠ  LangChain â€” éµå®ˆ SPEC-007 ç¦æ­¢äº‹é …
- ä¸åŠ  Neo4j æˆ–åœ–è³‡æ–™åº« â€” Pattern 6 å»¶å¾Œè‡³æ­£å¼ç‰ˆ
- ä¸æ”¹ `analyze()` å›å‚³ dict çµæ§‹ â€” ä¸‹æ¸¸ä¸è®Š
- ä¸æ”¹ `_MOCK_RECOMMENDATION` â€” SPEC-007 æ¸¬è©¦ä¾è³´æ­¤å¸¸æ•¸
- ä¸æ”¹ `database.py` â€” ä¸æ–°å¢ table æˆ– column
- ä¸å¯¦ä½œå¤šè¼ª LLM å°è©± â€” ç¶­æŒå–®æ¬¡å‘¼å«ï¼ˆæ¯æ¬¡ Orient ä¸€æ¬¡ API callï¼‰
- ä¸å¯¦ä½œ LLM æ‘˜è¦å£“ç¸®å™¨ â€” ç”¨ SQL LIMIT ä»£æ›¿

---

## ğŸ“ åƒè€ƒè³‡æ–™ï¼ˆReferencesï¼‰

- ADR-013ï¼š[Orient Prompt å·¥ç¨‹ç­–ç•¥](../adr/ADR-013-orient-prompt-engineering-strategy.md)
- ADR-005ï¼š[PentestGPT Orient å¼•æ“](../adr/ADR-005-pentestgpt-orient-engine.md)
- ADR-003ï¼š[OODA å¼•æ“æ¶æ§‹](../adr/ADR-003-ooda-loop-engine-architecture.md)
- SPEC-007ï¼š[OODA å¾ªç’°å¼•æ“](SPEC-007-ooda-loop-engine.md)

**å€Ÿé¡é–‹æºå°ˆæ¡ˆï¼š**

| å°ˆæ¡ˆ | æˆæ¬Š | å€Ÿé¡æ¨¡å¼ |
|------|------|----------|
| [PentestGPT](https://github.com/GreyDGL/PentestGPT) | MIT | Pattern 1: ä»»å‹™æ¨¹ / PTT |
| [hackingBuddyGPT](https://github.com/ipa-lab/hackingBuddyGPT) | MIT | Pattern 2: Action + Reflection |
| [autopentest-ai](https://github.com/bhavsec/autopentest-ai) | Apache 2.0 | Pattern 3: è§’è‰²åˆç´„ |
| [AttackGen](https://github.com/mrwadams/attackgen) | GPL-3.0 | Pattern 4: MITRE æ¥åœ°ï¼ˆç ”ç©¶åƒè€ƒï¼‰ |
| [Threats2MITRE](https://github.com/LiuYuancheng/Threats_2_MITRE_AI_Mapper) | MIT | Pattern 4: Kill Chain æ˜ å°„ |
| [PentAGI](https://github.com/vxcontrol/pentagi) | MIT | Pattern 5: ä¸‰å±¤è¨˜æ†¶ |
